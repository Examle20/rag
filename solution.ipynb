{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5ff1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa911cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m         abstract = (obj.get(\u001b[33m\"\u001b[39m\u001b[33mabstract\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m     15\u001b[39m         text = (title + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + abstract).strip()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         ids = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     17\u001b[39m         lens.append(\u001b[38;5;28mlen\u001b[39m(ids))\n\u001b[32m     19\u001b[39m arr = np.array(lens, dtype=np.int32)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rag_system\\rag\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2456\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, tokenizer_kwargs, **kwargs)\u001b[39m\n\u001b[32m   2454\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_switch_to_input_mode\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2455\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2456\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2465\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_switch_to_target_mode\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rag_system\\rag\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_tokenizers.py:856\u001b[39m, in \u001b[36mTokenizersBackend._encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m     \u001b[38;5;28mself\u001b[39m._tokenizer.encode_special_tokens = split_special_tokens\n\u001b[32m    855\u001b[39m \u001b[38;5;66;03m# Direct rust backend call\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;66;03m# Convert encodings to BatchEncoding format\u001b[39;00m\n\u001b[32m    863\u001b[39m tokens_and_encodings = [\n\u001b[32m    864\u001b[39m     \u001b[38;5;28mself\u001b[39m._convert_encoding(\n\u001b[32m    865\u001b[39m         encoding=encoding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    874\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[32m    875\u001b[39m ]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "PATH = \"arxiv-metadata-s.json\"\n",
    "MODEL = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "\n",
    "lens = []\n",
    "with open(PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for obj in ijson.items(f, \"item\"):\n",
    "        title = (obj.get(\"title\") or \"\").strip()\n",
    "        abstract = (obj.get(\"abstract\") or \"\").strip()\n",
    "        text = (title + \"\\n\" + abstract).strip()\n",
    "        ids = tokenizer(text, add_special_tokens=True, truncation=False)[\"input_ids\"]\n",
    "        lens.append(len(ids))\n",
    "\n",
    "arr = np.array(lens, dtype=np.int32)\n",
    "print(\"count:\", arr.size)\n",
    "print(\"mean tokens:\", float(arr.mean()))\n",
    "for p in [50, 90, 95, 99, 99.5, 99.9]:\n",
    "    print(f\"p{p}:\", float(np.percentile(arr, p)))\n",
    "print(\"max:\", int(arr.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedder_name: str = \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "        reranker_name: str = \"Qwen/Qwen3-Reranker-0.6B\",\n",
    "        chunk_size: int = 500,\n",
    "        chunk_overlap: int = 125,\n",
    "        device: Optional[str] = None,\n",
    "    ):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.emb_tokenizer = AutoTokenizer.from_pretrained(embedder_name)\n",
    "        self.embedder = AutoModel.from_pretrained(embedder_name).to(self.device)\n",
    "        self.embedder.eval()\n",
    "\n",
    "        self.rr_tokenizer = AutoTokenizer.from_pretrained(reranker_name, padding_side='left')\n",
    "        self.reranker = AutoModelForCausalLM.from_pretrained(reranker_name).to(self.device)\n",
    "        self.reranker.eval()\n",
    "\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap,)\n",
    "        self.index = None\n",
    "        self.doc_store = []\n",
    "\n",
    "        self.max_length = 1024\n",
    "        self.token_false_id = self.rr_tokenizer.convert_tokens_to_ids(\"no\")\n",
    "        self.token_true_id = self.rr_tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "        prefix = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \\\"yes\\\" or \\\"no\\\".<|im_end|>\\n<|im_start|>user\\n\"\n",
    "        suffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "        self.prefix_tokens = self.rr_tokenizer.encode(prefix, add_special_tokens=False)\n",
    "        self.suffix_tokens = self.rr_tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "    def _generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        inputs = self.emb_tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.embedder(**inputs)\n",
    "        embeddings = self.last_token_pool(outputs.last_hidden_state,\n",
    "                                          inputs.attention_mask).cpu()\n",
    "        return F.normalize(embeddings, p=2, dim=1).numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def last_token_pool(last_hidden_states: Tensor,\n",
    "                        attention_mask: Tensor) -> Tensor:\n",
    "        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        else:\n",
    "            sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "            batch_size = last_hidden_states.shape[0]\n",
    "            return last_hidden_states[\n",
    "                torch.arange(batch_size, device=last_hidden_states.device),\n",
    "                sequence_lengths] \n",
    "\n",
    "    def load_and_process_arxiv_json(self, file_path: str, split: bool = False) -> List[Document]:\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        if ext != \".json\":\n",
    "            raise ValueError(f\"Expected .json file, got: {ext}\")\n",
    "\n",
    "        docs: List[Document] = []\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for obj in ijson.items(f, \"item\"):\n",
    "                arxiv_id = obj.get(\"id\")\n",
    "                title = (obj.get(\"title\") or \"\").strip()\n",
    "                abstract = (obj.get(\"abstract\") or \"\").strip()\n",
    "                text = (title + \"\\n\" + abstract).strip()\n",
    "                meta = {\n",
    "                    \"id\": arxiv_id,\n",
    "                    \"title\": title,\n",
    "                    \"categories\": obj.get(\"categories\"),\n",
    "                    \"doi\": obj.get(\"doi\"),\n",
    "                    \"journal_ref\": obj.get(\"journal-ref\"),\n",
    "                    \"update_date\": obj.get(\"update_date\"),\n",
    "                }\n",
    "\n",
    "                docs.append(Document(page_content=text, metadata=meta))\n",
    "\n",
    "        return self.text_splitter.split_documents(docs) if split else docs\n",
    "\n",
    "    def build_index(self, file_path: str, batch_size: int = 64) -> None:\n",
    "        all_docs = self.load_and_process_arxiv_json(file_path, split=False)\n",
    "        self.doc_store = all_docs\n",
    "        embs = []\n",
    "        for i in range(0, len(all_docs), batch_size):\n",
    "            batch_texts = [d.page_content for d in all_docs[i:i + batch_size]]\n",
    "            embs.append(self._generate_embeddings(batch_texts))\n",
    "        embeddings = np.concatenate(embs, axis=0).astype(\"float32\")\n",
    "        self.index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_detailed_instruct(task_description: str, query: str):\n",
    "        return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "    @staticmethod\n",
    "    def format_reranker_instruction(query, doc, instruction=None):\n",
    "        if instruction is None:\n",
    "            instruction = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "        output = \"<Instruct>: {instruction}\\n<Query>: {query}\\n<Document>: {doc}\".format(\n",
    "            instruction=instruction, query=query, doc=doc)\n",
    "        return output\n",
    "\n",
    "    def process_inputs(self, pairs):\n",
    "        \"\"\"Обработка данных для реранкера\"\"\"\n",
    "        inputs = self.rr_tokenizer(pairs,\n",
    "                                   padding=False,\n",
    "                                   truncation='longest_first',\n",
    "                                   return_attention_mask=False,\n",
    "                                   max_length=self.max_length -\n",
    "                                   len(self.prefix_tokens) -\n",
    "                                   len(self.suffix_tokens))\n",
    "        for i, ele in enumerate(inputs['input_ids']):\n",
    "            inputs['input_ids'][\n",
    "                i] = self.prefix_tokens + ele + self.suffix_tokens\n",
    "        inputs = self.rr_tokenizer.pad(inputs,\n",
    "                                       padding=True,\n",
    "                                       return_tensors=\"pt\",\n",
    "                                       max_length=self.max_length)\n",
    "\n",
    "        # переносим тензоры на девайс ранжирующей модели\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to(self.device)\n",
    "        return inputs\n",
    "\n",
    "    def search(self,\n",
    "               query: str,\n",
    "               k: int = 5,\n",
    "               task: str = None):\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not initialized\")\n",
    "\n",
    "        if task is None:\n",
    "            task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "\n",
    "        query_embedding = self._generate_embeddings([query])\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        return distances, indices         \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_logits(self, inputs):\n",
    "        batch_scores = self.reranker(**inputs).logits[:, -1, :]\n",
    "        true_vector = batch_scores[:, self.token_true_id]\n",
    "        false_vector = batch_scores[:, self.token_false_id]\n",
    "        batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "        batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "        scores = batch_scores[:, 1].exp().tolist()\n",
    "        return scores\n",
    "\n",
    "    def rerank(self, query: str, documents: List[str], batch_size=4):\n",
    "        pairs = []\n",
    "        for d in documents:\n",
    "            pairs.append(self.format_reranker_instruction(query, d))\n",
    "\n",
    "        scores = []\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "            inputs = self.process_inputs(pairs[i:i + batch_size])\n",
    "            sc = self.compute_logits(inputs)\n",
    "            scores.extend(sc)\n",
    "        return scores            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6619bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 310/310 [00:00<00:00, 1517.06it/s, Materializing param=norm.weight]                              \n",
      "Loading weights: 100%|██████████| 310/310 [00:00<00:00, 1338.27it/s, Materializing param=model.norm.weight]                              \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Got unsupported ScalarType BFloat16",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m k = \u001b[32m5\u001b[39m\n\u001b[32m      4\u001b[39m rag = RAG(device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mrag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./arxiv-metadata-s.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m D, I = rag.search(q, k=k)\n\u001b[32m      8\u001b[39m candidates = [rag.doc_store[i].page_content \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I[\u001b[32m0\u001b[39m]]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mRAG.build_index\u001b[39m\u001b[34m(self, file_path, batch_size)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(all_docs), batch_size):\n\u001b[32m     92\u001b[39m     batch_texts = [d.page_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m all_docs[i:i + batch_size]]\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     embs.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     94\u001b[39m embeddings = np.concatenate(embs, axis=\u001b[32m0\u001b[39m).astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.index = faiss.IndexFlatIP(embeddings.shape[\u001b[32m1\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mRAG._generate_embeddings\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     44\u001b[39m inputs.to(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.last_token_pool(outputs.last_hidden_state,\n\u001b[32m     46\u001b[39m                                   inputs.attention_mask).cpu()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Got unsupported ScalarType BFloat16"
     ]
    }
   ],
   "source": [
    "q = \"Keldysh formalism Andreev current heavy fermions\"\n",
    "\n",
    "k = 5\n",
    "rag = RAG(device=\"cuda\")\n",
    "rag.build_index(\"./arxiv-metadata-s.json\")\n",
    "\n",
    "D, I = rag.search(q, k=k)\n",
    "candidates = [rag.doc_store[i].page_content for i in I[0]]\n",
    "\n",
    "for c in candidates:\n",
    "    print(c[:800])  # чтобы не печатать всё\n",
    "    print(\"-#\" * 20)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
